# Multi-agent Model - Individual Project
- Mesa docs → https://mesa.readthedocs.io/latest/

- Mesa Network Grid docs → https://mesa.readthedocs.io/latest/apis/space.html#mesa.space.NetworkGrid \

- NetworkX docs → https://networkx.org/documentation/stable/ \

- Exploring Network Structure, Dynamics, and Function using NetworkX → http://conference.scipy.org.s3-website-us-east-1.amazonaws.com/proceedings/scipy2008/paper_2/ \

- Mesa GitHub with Network example → https://github.com/mesa/mesa/tree/main

# Previous work
- PREVIOUS RESEARCH PAPER → https://link.springer.com/article/10.1007/s00146-022-01626-5

This paper presents a multi-agent social simulation that models how information sharing on social networks influences user satisfaction and opinion polarization. It uses Social Judgment Theory to represent how agents update their attitudes through interactions, and experiments show that greater tolerance among users slows polarization but reduces satisfaction, while stronger selective exposure (echo chambers) increases polarization and reduces reach, leading to more homophilic network structures.

- PREVIOUS RESEARCH CODE → https://github.com/ahaque2/MultiAgent_Social_Simulation/tree/main

This code repository implements the simulation described above, providing the source code for the multi-agent social network model and datasets.

- PREVIOUS RESEARCH DATA → https://snap.stanford.edu/data/egonets-Facebook.html

The Stanford SNAP “ego-networks” Facebook dataset consists of anonymized social circles and relationship graphs from Facebook users, including node attributes and friendship ties. It’s commonly used in social network analysis to study structures like community formation, clustering, and diffusion patterns, making it useful for validating agent interactions or network effects in simulations. This is the data used for the simulation described above.

- MISINFORMATION SPREAD RESEARCH → https://www.science.org/doi/10.1126/science.aap9559

This large-scale empirical study finds that false news spreads farther, faster, deeper, and more broadly on social media than true news, primarily due to human behaviour rather than automated bots. It highlights that misinformation has distinct dynamics from truthful information, shaping how online information cascades form and persist, which is crucial for modelling fake news spread and intervention strategies.

- SIMULATING MISINFORMATION VULNERABILITIES WITH AGENT PERSONAS → https://arxiv.org/pdf/2511.04697

This recent research develops an agent-based simulation using LLM-generated agent personas to study responses to misinformation. By assigning agents diverse mental schemas and professional backgrounds, it shows that mental models more strongly shape how misinformation is interpreted than job roles, validating LLM agents as proxies for human reactions and offering a foundation for exploring trust, polarization, and susceptibility to deceptive content.
